{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Data Warehouse\n",
    "Samuel Botter Martins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook aims to inspect the dataset provided by the project. Although the project description presents a lot of information about the datasets, such as their links and structures, I decided to double-check them to practice my coding skills with boto3 and S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start\n",
    "First, I followed the same steps as in the Exercise about IaC and created a new IAM user in my AWS account with _AdministrationAccess_. <br/>\n",
    "I then used my _security credentials (access keys)_ to follow this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load DWH Parameters from a configuration file\n",
    "My AWS configuration is placed in the `dwh.cfg` file. For security reasons, I have just provided a template of this file called `dwh_template.cfg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY = config.get('AWS', 'KEY')\n",
    "SECRET = config.get('AWS', 'SECRET')\n",
    "REGION = config.get('AWS', 'REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the loaded parameters\n",
    "# uncomment the code below to show your credentials\n",
    "\n",
    "# pd.DataFrame({\n",
    "#     \"param\": ['KEY', 'SECRET', 'REGION_NAME',],\n",
    "#     \"value\": [KEY, SECRET, REGION_NAME],\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an S3 Client for S3\n",
    "I'm going to create an python client for S3 to access the S3 bucket provided by the project. <br/>\n",
    "We can do this using two different methods:\n",
    "- `boto3.client`\n",
    "- `boto3.resource`\n",
    "\n",
    "In summary, the `client` method is best suited for _making direct API calls_ and offers **fine-grained control**, while the `resource` method provides a _higher-level interface_ and allows you to work with AWS resources using a _more object-oriented approach_.\n",
    "\n",
    "More details at: https://www.learnaws.org/2021/02/24/boto3-resource-client/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use both methods at different times, according to available methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 A bit about S3\n",
    "Before checking out the datasets, let's recap some concepts about **S3**.\n",
    "\n",
    "A <span style='color: orange'><b>S3 bucket</b></span> is a logical _container_ of <span style='color: #d13212'>objects</span>. That would be a ***“folder”***, but since **S3 deals with objects and _not_ files**, the distinction becomes important.\n",
    "\n",
    "A <span style='color: #d13212'>Objects</span> is similar to a \"file\", but with a _different structure_ on AWS. <span style='color: #d13212'>Objects</span> are a **name/value data pair**, or the **“content”** and **metadata**.\n",
    "\n",
    "For privacy reasons, Amazon **cannot see the _data_** inside any object, but **can see the _metadata_**. The **metadata** is a *series of information about the object itself* such as last modified date, file size and other HTTP specific metadata.\n",
    "\n",
    "_Object identification_ is a <span style='color: #d13212'><b>key name</b></span> that _uniquely identifies_ each object within a bucket. We use the <span style='color: #d13212'><b>object key</b></span> to retrieve the object.\n",
    "\n",
    "<span style='color: orange'><b>Amazon S3</b></span> has a ***flat structure*** rather than a hierarchy like you would see in a file system. However, the <span style='color: orange'><b>Amazon S3</b></span> console **supports the _folder concept_** as a means of **object grouping**.\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understanding the datasets\n",
    "The project description mentions that we will be working with 3 datasets residing in a public S3 bucket, with the following S3 links:\n",
    "- Song data: `s3://udacity-dend/song_data`\n",
    "- Log data: `s3://udacity-dend/log_data`\n",
    "- This third file `s3://udacity-dend/log_json_path.json` contains the _meta information_ that is required by AWS to correctly load `s3://udacity-dend/log_data`\n",
    "\n",
    "According to the [official AWS documentation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-bucket-intro.html), one possible way to access an S3 bucket is using the format `s3 ://`, which is exactly our case. We should **be aware** that when using this format, the _bucket name_ **does not include the *AWS Region***.\n",
    "<br/>\n",
    "\n",
    "<code>s3://</code><code style='color: #d13212'>bucket-name</code><code>/</code><code style='color: #d13212'>key-name</code>\n",
    "\n",
    "For example: <br/>\n",
    "<code>S3://mybucket/puppy.jpg</code>\n",
    "\n",
    "In our case, the **bucket** is <code style='color: #d13212'>udacity-dend</code> and apparently it has some 'folder', like `song_data` and `log_data`. tHE **bucket region** mentioned in the project description is `us-west-2`. I will create the Redshift cluster in the same region. So, I put this information in my _configuration file_.\n",
    "\n",
    "Also, I created the `BUCKET='udacity-dend'` setting in the `dwh.cfg` file.\n",
    "\n",
    "Let's confirm these premises.\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing all objects ('files') inside the `udacity-dend` bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a S3 client via boto3.resource\n",
    "s3 = boto3.resource('s3',\n",
    "                    region_name=REGION,\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access/get the S3 bucket\n",
    "bucket = s3.Bucket('udacity-dend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all objects' names ('filenames') inside this bucket\n",
    "for obj in bucket.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this run was too long, I stopped after a few seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this run, we can confirm some assumptions about our _bucket_:\n",
    "- `log-data` and `song-data` are 'folders'\n",
    "- They have specific _subfolder structures_.\n",
    "- The bucket also includes other files and folders irrelevant to our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing objects from a specific 'folder'\n",
    "We have two ways for that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `boto3.resource` with `filter` and `prefix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `bucket` was previously loaded with `boto3.resource`\n",
    "\n",
    "for obj in bucket.objects.filter(Prefix=\"log_data\"):\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `boto3.client` and recovering the specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a S3 client via boto3.client\n",
    "s3_client = boto3.client('s3',\n",
    "                         region_name=REGION,\n",
    "                         aws_access_key_id=KEY,\n",
    "                         aws_secret_access_key=SECRET)\n",
    "\n",
    "# getting all objects with prefix `log_data` inside the bucket `udacity-dend`\n",
    "objects = s3_client.list_objects_v2(Bucket='udacity-dend', Prefix=\"log_data\")\n",
    "\n",
    "for obj in objects['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BE CAREFUL\n",
    "In both cases, we are retrieving the objects inside a _'folder'_ using a **prefix**. We then inform you that the name of the folder is this _prefix_.\n",
    "\n",
    "However, please note that this does not guarantee that only files in this folder will be recovered. Any other files or directories with the same prefix will also be recovered.\n",
    "\n",
    "For example, an object with filename `log_data_full.csv` would also be retrieved in the examples above.\n",
    "\n",
    "More details:\n",
    "- https://dev.to/aws-builders/how-to-list-contents-of-s3-bucket-using-boto3-python-47mm\n",
    "- https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/list_objects_v2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and inspecting a specific file of each dataset\n",
    "Finally, let's download and inspect a specific file from each dataset. <br/>\n",
    "Let's consider the files:\n",
    "- `log_data/2018/11/2018-11-01-events.json`\n",
    "- `song-data/A/N/S/TRANSJO128F1458706.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a S3 client via boto3.resource\n",
    "s3 = boto3.resource('s3',\n",
    "                    region_name=REGION,\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET)\n",
    "\n",
    "# access/get the S3 bucket\n",
    "bucket = s3.Bucket('udacity-dend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the sample files in a `sample`` folder\n",
    "bucket.download_file('song-data/A/N/S/TRANSJO128F1458706.json', './samples/song_data_sample.json')\n",
    "bucket.download_file('log_data/2018/11/2018-11-01-events.json', './samples/log_data_sample.json')\n",
    "\n",
    "# download the third dataset\n",
    "bucket.download_file('log_json_path.json', './samples/log_json_path.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SONG DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the json files as pandas dataframes\n",
    "# SONG DATA\n",
    "pd.read_json('./samples/song_data_sample.json', orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOG DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG Data\n",
    "pd.read_json('./samples/log_data_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> <br/>\n",
    "\n",
    "Now I can work on designing the tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
